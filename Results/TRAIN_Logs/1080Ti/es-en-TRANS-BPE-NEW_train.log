[2019-10-06 18:17:21,832 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.train.0.pt
[2019-10-06 18:17:21,902 INFO]  * src vocab size = 48887
[2019-10-06 18:17:21,902 INFO]  * tgt vocab size = 47030
[2019-10-06 18:17:21,902 INFO] Building model...
[2019-10-06 18:17:26,846 INFO] NMTModel(
  (encoder): TransformerEncoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(48887, 512, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (transformer): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
  )
  (decoder): TransformerDecoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(47030, 512, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (transformer_layers): ModuleList(
      (0): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (3): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (4): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (5): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
    )
    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
  )
  (generator): Sequential(
    (0): Linear(in_features=512, out_features=47030, bias=True)
    (1): Cast()
    (2): LogSoftmax()
  )
)
[2019-10-06 18:17:26,849 INFO] encoder: 43945472
[2019-10-06 18:17:26,849 INFO] decoder: 73430966
[2019-10-06 18:17:26,849 INFO] * number of parameters: 117376438
[2019-10-06 18:17:26,851 INFO] Starting training on GPU: [0, 1, 2, 3]
[2019-10-06 18:17:26,851 INFO] Start training loop and validate every 500 steps...
[2019-10-06 18:17:34,919 INFO] number of examples: 892901
[2019-10-06 18:19:28,603 INFO] Step 100/202000; acc:   5.06; ppl: 3673.29; xent: 8.21; lr: 0.00010; 24176/24015 tok/s;    122 sec
[2019-10-06 18:21:08,720 INFO] Step 200/202000; acc:   7.88; ppl: 321.19; xent: 5.77; lr: 0.00020; 29407/29156 tok/s;    222 sec
[2019-10-06 18:22:49,648 INFO] Step 300/202000; acc:  15.49; ppl: 177.48; xent: 5.18; lr: 0.00030; 29011/29008 tok/s;    323 sec
[2019-10-06 18:24:30,079 INFO] Step 400/202000; acc:  20.91; ppl: 106.16; xent: 4.66; lr: 0.00040; 29139/29074 tok/s;    423 sec
[2019-10-06 18:26:10,852 INFO] Step 500/202000; acc:  23.93; ppl: 80.46; xent: 4.39; lr: 0.00050; 28986/28686 tok/s;    524 sec
[2019-10-06 18:26:10,853 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.valid.0.pt
[2019-10-06 18:26:10,886 INFO] number of examples: 5006
[2019-10-06 18:26:18,698 INFO] Validation perplexity: 123.884
[2019-10-06 18:26:18,698 INFO] Validation accuracy: 25.8811
[2019-10-06 18:26:18,698 INFO] Model is improving acc: -inf --> 25.8811.
[2019-10-06 18:26:18,698 INFO] Model is improving ppl: inf --> 123.884.
[2019-10-06 18:26:18,931 INFO] Saving checkpoint /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/model/model_step_500.pt
[2019-10-06 18:27:12,169 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.train.1.pt
[2019-10-06 20:16:16,643 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.train.0.pt
[2019-10-06 20:16:17,652 INFO]  * src vocab size = 48887
[2019-10-06 20:16:17,653 INFO]  * tgt vocab size = 47030
[2019-10-06 20:16:17,655 INFO] Building model...
[2019-10-06 20:16:22,449 INFO] NMTModel(
  (encoder): TransformerEncoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(48887, 512, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (transformer): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
  )
  (decoder): TransformerDecoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(47030, 512, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (transformer_layers): ModuleList(
      (0): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (3): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (4): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
      (5): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1, inplace=False)
      )
    )
    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
  )
  (generator): Sequential(
    (0): Linear(in_features=512, out_features=47030, bias=True)
    (1): Cast()
    (2): LogSoftmax()
  )
)
[2019-10-06 20:16:22,452 INFO] encoder: 43945472
[2019-10-06 20:16:22,452 INFO] decoder: 73430966
[2019-10-06 20:16:22,452 INFO] * number of parameters: 117376438
[2019-10-06 20:16:22,454 INFO] Starting training on GPU: [0, 1, 2, 3]
[2019-10-06 20:16:22,454 INFO] Start training loop and validate every 500 steps...
[2019-10-06 20:16:29,510 INFO] number of examples: 892901
[2019-10-06 20:18:24,483 INFO] Step 100/202000; acc:   5.23; ppl: 3589.16; xent: 8.19; lr: 0.00010; 23965/23966 tok/s;    122 sec
[2019-10-06 20:20:05,514 INFO] Step 200/202000; acc:   7.78; ppl: 321.30; xent: 5.77; lr: 0.00020; 28981/28751 tok/s;    223 sec
[2019-10-06 20:21:47,129 INFO] Step 300/202000; acc:  15.59; ppl: 180.37; xent: 5.19; lr: 0.00030; 28901/28905 tok/s;    325 sec
[2019-10-06 20:23:28,214 INFO] Step 400/202000; acc:  20.98; ppl: 105.86; xent: 4.66; lr: 0.00040; 29147/28971 tok/s;    426 sec
[2019-10-06 20:25:09,486 INFO] Step 500/202000; acc:  24.10; ppl: 78.92; xent: 4.37; lr: 0.00050; 28885/28771 tok/s;    527 sec
[2019-10-06 20:25:09,487 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.valid.0.pt
[2019-10-06 20:25:09,520 INFO] number of examples: 5006
[2019-10-06 20:25:16,958 INFO] Validation perplexity: 123.002
[2019-10-06 20:25:16,958 INFO] Validation accuracy: 25.8656
[2019-10-06 20:25:16,958 INFO] Model is improving ppl: inf --> 123.002.
[2019-10-06 20:25:16,958 INFO] Model is improving acc: -inf --> 25.8656.
[2019-10-06 20:25:17,169 INFO] Saving checkpoint /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/model/model_step_500.pt
[2019-10-06 20:26:16,718 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.train.1.pt
[2019-10-06 20:26:22,667 INFO] number of examples: 421684
[2019-10-06 20:27:06,347 INFO] Step 600/202000; acc:  27.23; ppl: 60.60; xent: 4.10; lr: 0.00059; 24903/24719 tok/s;    644 sec
[2019-10-06 20:28:47,958 INFO] Step 700/202000; acc:  31.77; ppl: 43.80; xent: 3.78; lr: 0.00069; 28538/28399 tok/s;    746 sec
[2019-10-06 20:30:29,472 INFO] Step 800/202000; acc:  36.94; ppl: 31.36; xent: 3.45; lr: 0.00079; 28795/28659 tok/s;    847 sec
[2019-10-06 20:32:11,379 INFO] Step 900/202000; acc:  41.66; ppl: 22.96; xent: 3.13; lr: 0.00089; 28545/28367 tok/s;    949 sec
[2019-10-06 20:32:18,581 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.train.0.pt
[2019-10-06 20:32:37,592 INFO] number of examples: 892901
[2019-10-06 20:33:53,082 INFO] Step 1000/202000; acc:  46.42; ppl: 16.75; xent: 2.82; lr: 0.00099; 28748/28715 tok/s;   1051 sec
[2019-10-06 20:33:53,082 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.valid.0.pt
[2019-10-06 20:33:53,152 INFO] number of examples: 5006
[2019-10-06 20:34:00,488 INFO] Validation perplexity: 18.9801
[2019-10-06 20:34:00,488 INFO] Validation accuracy: 49.9707
[2019-10-06 20:34:00,488 INFO] Model is improving ppl: 123.002 --> 18.9801.
[2019-10-06 20:34:00,488 INFO] Model is improving acc: 25.8656 --> 49.9707.
[2019-10-06 20:34:00,713 INFO] Saving checkpoint /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/model/model_step_1000.pt
[2019-10-06 20:35:43,689 INFO] Step 1100/202000; acc:  49.81; ppl: 13.23; xent: 2.58; lr: 0.00109; 26481/26312 tok/s;   1161 sec
[2019-10-06 20:37:25,437 INFO] Step 1200/202000; acc:  53.07; ppl: 10.64; xent: 2.36; lr: 0.00119; 28699/28705 tok/s;   1263 sec
[2019-10-06 20:39:07,287 INFO] Step 1300/202000; acc:  55.01; ppl:  9.31; xent: 2.23; lr: 0.00129; 28784/28536 tok/s;   1365 sec
[2019-10-06 20:40:49,072 INFO] Step 1400/202000; acc:  57.37; ppl:  8.04; xent: 2.08; lr: 0.00138; 28845/28804 tok/s;   1467 sec
[2019-10-06 20:42:30,621 INFO] Step 1500/202000; acc:  58.38; ppl:  7.46; xent: 2.01; lr: 0.00148; 28982/28899 tok/s;   1568 sec
[2019-10-06 20:42:30,622 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.valid.0.pt
[2019-10-06 20:42:30,661 INFO] number of examples: 5006
[2019-10-06 20:42:38,071 INFO] Validation perplexity: 8.04254
[2019-10-06 20:42:38,071 INFO] Validation accuracy: 61.3637
[2019-10-06 20:42:38,071 INFO] Model is improving ppl: 18.9801 --> 8.04254.
[2019-10-06 20:42:38,071 INFO] Model is improving acc: 49.9707 --> 61.3637.
[2019-10-06 20:42:38,280 INFO] Saving checkpoint /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/model/model_step_1500.pt
[2019-10-06 20:44:21,669 INFO] Step 1600/202000; acc:  59.57; ppl:  6.93; xent: 1.94; lr: 0.00158; 26381/26235 tok/s;   1679 sec
[2019-10-06 20:45:20,440 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.train.1.pt
[2019-10-06 20:45:27,094 INFO] number of examples: 421684
[2019-10-06 20:46:03,158 INFO] Step 1700/202000; acc:  60.58; ppl:  6.48; xent: 1.87; lr: 0.00168; 28696/28511 tok/s;   1781 sec
[2019-10-06 20:47:45,068 INFO] Step 1800/202000; acc:  61.33; ppl:  6.16; xent: 1.82; lr: 0.00178; 28385/28213 tok/s;   1883 sec
[2019-10-06 20:49:26,665 INFO] Step 1900/202000; acc:  62.53; ppl:  5.73; xent: 1.75; lr: 0.00188; 28797/28673 tok/s;   1984 sec
[2019-10-06 20:51:08,360 INFO] Step 2000/202000; acc:  62.93; ppl:  5.58; xent: 1.72; lr: 0.00198; 28597/28449 tok/s;   2086 sec
[2019-10-06 20:51:08,361 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.valid.0.pt
[2019-10-06 20:51:08,405 INFO] number of examples: 5006
[2019-10-06 20:51:15,883 INFO] Validation perplexity: 6.13008
[2019-10-06 20:51:15,883 INFO] Validation accuracy: 65.0136
[2019-10-06 20:51:15,883 INFO] Model is improving ppl: 8.04254 --> 6.13008.
[2019-10-06 20:51:15,883 INFO] Model is improving acc: 61.3637 --> 65.0136.
[2019-10-06 20:51:16,092 INFO] Saving checkpoint /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/model/model_step_2000.pt
[2019-10-06 20:51:31,830 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.train.0.pt
[2019-10-06 20:51:49,450 INFO] number of examples: 892901
[2019-10-06 20:52:59,057 INFO] Step 2100/202000; acc:  63.79; ppl:  5.28; xent: 1.66; lr: 0.00193; 26457/26342 tok/s;   2197 sec
[2019-10-06 20:54:41,094 INFO] Step 2200/202000; acc:  64.38; ppl:  5.08; xent: 1.62; lr: 0.00188; 28659/28516 tok/s;   2299 sec
[2019-10-06 20:56:23,062 INFO] Step 2300/202000; acc:  65.21; ppl:  4.83; xent: 1.57; lr: 0.00184; 28670/28651 tok/s;   2401 sec
[2019-10-06 20:58:05,486 INFO] Step 2400/202000; acc:  65.50; ppl:  4.72; xent: 1.55; lr: 0.00180; 28609/28444 tok/s;   2503 sec
[2019-10-06 20:59:47,318 INFO] Step 2500/202000; acc:  66.31; ppl:  4.49; xent: 1.50; lr: 0.00177; 28854/28758 tok/s;   2605 sec
[2019-10-06 20:59:47,319 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.valid.0.pt
[2019-10-06 20:59:47,386 INFO] number of examples: 5006
[2019-10-06 20:59:54,893 INFO] Validation perplexity: 5.02288
[2019-10-06 20:59:54,893 INFO] Validation accuracy: 67.8194
[2019-10-06 20:59:54,893 INFO] Model is improving ppl: 6.13008 --> 5.02288.
[2019-10-06 20:59:54,893 INFO] Model is improving acc: 65.0136 --> 67.8194.
[2019-10-06 20:59:55,100 INFO] Saving checkpoint /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/model/model_step_2500.pt
[2019-10-06 21:01:38,018 INFO] Step 2600/202000; acc:  66.47; ppl:  4.44; xent: 1.49; lr: 0.00173; 26549/26488 tok/s;   2716 sec
[2019-10-06 21:03:19,632 INFO] Step 2700/202000; acc:  66.81; ppl:  4.33; xent: 1.47; lr: 0.00170; 28862/28738 tok/s;   2817 sec
[2019-10-06 21:04:25,705 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.train.1.pt
[2019-10-06 21:04:35,340 INFO] number of examples: 421684
[2019-10-06 21:05:01,290 INFO] Step 2800/202000; acc:  67.20; ppl:  4.23; xent: 1.44; lr: 0.00167; 28619/28426 tok/s;   2919 sec
[2019-10-06 21:06:43,468 INFO] Step 2900/202000; acc:  67.43; ppl:  4.16; xent: 1.43; lr: 0.00164; 28366/28144 tok/s;   3021 sec
[2019-10-06 21:08:25,061 INFO] Step 3000/202000; acc:  68.07; ppl:  4.01; xent: 1.39; lr: 0.00161; 28796/28626 tok/s;   3123 sec
[2019-10-06 21:08:25,062 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.valid.0.pt
[2019-10-06 21:08:25,095 INFO] number of examples: 5006
[2019-10-06 21:08:32,565 INFO] Validation perplexity: 4.53346
[2019-10-06 21:08:32,565 INFO] Validation accuracy: 69.3601
[2019-10-06 21:08:32,566 INFO] Model is improving ppl: 5.02288 --> 4.53346.
[2019-10-06 21:08:32,566 INFO] Model is improving acc: 67.8194 --> 69.3601.
[2019-10-06 21:08:32,775 INFO] Saving checkpoint /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/model/model_step_3000.pt
[2019-10-06 21:10:16,010 INFO] Step 3100/202000; acc:  68.10; ppl:  3.99; xent: 1.38; lr: 0.00159; 26221/26136 tok/s;   3234 sec
[2019-10-06 21:10:37,503 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.train.0.pt
[2019-10-06 21:10:58,961 INFO] number of examples: 892901
[2019-10-06 21:11:57,999 INFO] Step 3200/202000; acc:  68.55; ppl:  3.88; xent: 1.36; lr: 0.00156; 28676/28602 tok/s;   3336 sec
[2019-10-06 21:13:39,794 INFO] Step 3300/202000; acc:  68.77; ppl:  3.83; xent: 1.34; lr: 0.00154; 28692/28526 tok/s;   3437 sec
[2019-10-06 21:15:21,929 INFO] Step 3400/202000; acc:  69.00; ppl:  3.77; xent: 1.33; lr: 0.00152; 28639/28600 tok/s;   3539 sec
[2019-10-06 21:17:04,392 INFO] Step 3500/202000; acc:  69.20; ppl:  3.73; xent: 1.32; lr: 0.00149; 28598/28504 tok/s;   3642 sec
[2019-10-06 21:17:04,392 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.valid.0.pt
[2019-10-06 21:17:04,462 INFO] number of examples: 5006
[2019-10-06 21:17:11,869 INFO] Validation perplexity: 4.26967
[2019-10-06 21:17:11,869 INFO] Validation accuracy: 70.251
[2019-10-06 21:17:11,869 INFO] Model is improving ppl: 4.53346 --> 4.26967.
[2019-10-06 21:17:11,869 INFO] Model is improving acc: 69.3601 --> 70.251.
[2019-10-06 21:17:12,081 INFO] Saving checkpoint /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/model/model_step_3500.pt
[2019-10-06 21:18:55,938 INFO] Step 3600/202000; acc:  69.40; ppl:  3.68; xent: 1.30; lr: 0.00147; 26333/26180 tok/s;   3753 sec
[2019-10-06 21:20:37,864 INFO] Step 3700/202000; acc:  69.59; ppl:  3.64; xent: 1.29; lr: 0.00145; 28853/28772 tok/s;   3855 sec
[2019-10-06 21:22:20,098 INFO] Step 3800/202000; acc:  69.56; ppl:  3.63; xent: 1.29; lr: 0.00143; 28701/28556 tok/s;   3958 sec
[2019-10-06 21:23:34,244 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.train.1.pt
[2019-10-06 21:23:41,155 INFO] number of examples: 421684
[2019-10-06 21:24:01,797 INFO] Step 3900/202000; acc:  69.69; ppl:  3.60; xent: 1.28; lr: 0.00142; 28601/28462 tok/s;   4059 sec
[2019-10-06 21:25:43,504 INFO] Step 4000/202000; acc:  69.94; ppl:  3.54; xent: 1.27; lr: 0.00140; 28527/28294 tok/s;   4161 sec
[2019-10-06 21:25:43,504 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.valid.0.pt
[2019-10-06 21:25:43,535 INFO] number of examples: 5006
[2019-10-06 21:25:50,931 INFO] Validation perplexity: 4.05636
[2019-10-06 21:25:50,931 INFO] Validation accuracy: 70.9805
[2019-10-06 21:25:50,932 INFO] Model is improving ppl: 4.26967 --> 4.05636.
[2019-10-06 21:25:50,932 INFO] Model is improving acc: 70.251 --> 70.9805.
[2019-10-06 21:25:51,142 INFO] Saving checkpoint /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/model/model_step_4000.pt
[2019-10-06 21:27:34,567 INFO] Step 4100/202000; acc:  70.38; ppl:  3.47; xent: 1.24; lr: 0.00138; 26287/26147 tok/s;   4272 sec
[2019-10-06 21:29:16,862 INFO] Step 4200/202000; acc:  70.31; ppl:  3.47; xent: 1.24; lr: 0.00136; 28436/28359 tok/s;   4374 sec
[2019-10-06 21:29:45,255 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.train.0.pt
[2019-10-06 21:30:04,453 INFO] number of examples: 892901
[2019-10-06 21:30:58,328 INFO] Step 4300/202000; acc:  70.56; ppl:  3.42; xent: 1.23; lr: 0.00135; 28806/28749 tok/s;   4476 sec
[2019-10-06 21:32:40,413 INFO] Step 4400/202000; acc:  70.79; ppl:  3.37; xent: 1.22; lr: 0.00133; 28665/28457 tok/s;   4578 sec
[2019-10-06 21:34:22,697 INFO] Step 4500/202000; acc:  70.79; ppl:  3.37; xent: 1.21; lr: 0.00132; 28619/28599 tok/s;   4680 sec
[2019-10-06 21:34:22,698 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.valid.0.pt
[2019-10-06 21:34:22,772 INFO] number of examples: 5006
[2019-10-06 21:34:30,191 INFO] Validation perplexity: 3.90134
[2019-10-06 21:34:30,191 INFO] Validation accuracy: 71.6295
[2019-10-06 21:34:30,191 INFO] Model is improving ppl: 4.05636 --> 3.90134.
[2019-10-06 21:34:30,191 INFO] Model is improving acc: 70.9805 --> 71.6295.
[2019-10-06 21:34:30,402 INFO] Saving checkpoint /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/model/model_step_4500.pt
[2019-10-06 21:36:13,632 INFO] Step 4600/202000; acc:  70.96; ppl:  3.33; xent: 1.20; lr: 0.00130; 26433/26248 tok/s;   4791 sec
[2019-10-06 21:37:56,190 INFO] Step 4700/202000; acc:  71.04; ppl:  3.31; xent: 1.20; lr: 0.00129; 28561/28535 tok/s;   4894 sec
[2019-10-06 21:39:38,595 INFO] Step 4800/202000; acc:  71.21; ppl:  3.29; xent: 1.19; lr: 0.00128; 28734/28565 tok/s;   4996 sec
[2019-10-06 21:41:20,660 INFO] Step 4900/202000; acc:  71.16; ppl:  3.29; xent: 1.19; lr: 0.00126; 28773/28658 tok/s;   5098 sec
[2019-10-06 21:42:42,301 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.train.1.pt
[2019-10-06 21:42:52,950 INFO] number of examples: 421684
[2019-10-06 21:43:03,006 INFO] Step 5000/202000; acc:  71.12; ppl:  3.29; xent: 1.19; lr: 0.00125; 28417/28294 tok/s;   5201 sec
[2019-10-06 21:43:03,007 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.valid.0.pt
[2019-10-06 21:43:03,038 INFO] number of examples: 5006
[2019-10-06 21:43:10,471 INFO] Validation perplexity: 3.83476
[2019-10-06 21:43:10,471 INFO] Validation accuracy: 71.9502
[2019-10-06 21:43:10,471 INFO] Model is improving ppl: 3.90134 --> 3.83476.
[2019-10-06 21:43:10,471 INFO] Model is improving acc: 71.6295 --> 71.9502.
[2019-10-06 21:43:10,681 INFO] Saving checkpoint /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/model/model_step_5000.pt
[2019-10-06 21:44:53,677 INFO] Step 5100/202000; acc:  71.43; ppl:  3.23; xent: 1.17; lr: 0.00124; 26225/26046 tok/s;   5311 sec
[2019-10-06 21:46:35,552 INFO] Step 5200/202000; acc:  71.70; ppl:  3.19; xent: 1.16; lr: 0.00123; 28641/28474 tok/s;   5413 sec
[2019-10-06 21:48:17,700 INFO] Step 5300/202000; acc:  71.63; ppl:  3.20; xent: 1.16; lr: 0.00121; 28434/28387 tok/s;   5515 sec
[2019-10-06 21:48:53,526 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.train.0.pt
[2019-10-06 21:49:11,100 INFO] number of examples: 892901
[2019-10-06 21:50:00,106 INFO] Step 5400/202000; acc:  71.83; ppl:  3.16; xent: 1.15; lr: 0.00120; 28581/28428 tok/s;   5618 sec
[2019-10-06 21:51:42,164 INFO] Step 5500/202000; acc:  72.01; ppl:  3.13; xent: 1.14; lr: 0.00119; 28669/28526 tok/s;   5720 sec
[2019-10-06 21:51:42,165 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.valid.0.pt
[2019-10-06 21:51:42,199 INFO] number of examples: 5006
[2019-10-06 21:51:49,611 INFO] Validation perplexity: 3.73099
[2019-10-06 21:51:49,611 INFO] Validation accuracy: 72.4152
[2019-10-06 21:51:49,611 INFO] Model is improving ppl: 3.83476 --> 3.73099.
[2019-10-06 21:51:49,611 INFO] Model is improving acc: 71.9502 --> 72.4152.
[2019-10-06 21:51:49,822 INFO] Saving checkpoint /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/model/model_step_5500.pt
[2019-10-06 21:53:33,243 INFO] Step 5600/202000; acc:  72.10; ppl:  3.11; xent: 1.14; lr: 0.00118; 26354/26330 tok/s;   5831 sec
[2019-10-06 21:55:15,148 INFO] Step 5700/202000; acc:  72.14; ppl:  3.10; xent: 1.13; lr: 0.00117; 28771/28588 tok/s;   5933 sec
[2019-10-06 21:56:57,948 INFO] Step 5800/202000; acc:  72.18; ppl:  3.09; xent: 1.13; lr: 0.00116; 28497/28433 tok/s;   6035 sec
[2019-10-06 21:58:39,437 INFO] Step 5900/202000; acc:  72.36; ppl:  3.06; xent: 1.12; lr: 0.00115; 29020/28800 tok/s;   6137 sec
[2019-10-06 22:00:21,487 INFO] Step 6000/202000; acc:  72.27; ppl:  3.07; xent: 1.12; lr: 0.00114; 28761/28627 tok/s;   6239 sec
[2019-10-06 22:00:21,488 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.valid.0.pt
[2019-10-06 22:00:21,555 INFO] number of examples: 5006
[2019-10-06 22:00:28,948 INFO] Validation perplexity: 3.66355
[2019-10-06 22:00:28,948 INFO] Validation accuracy: 72.568
[2019-10-06 22:00:28,948 INFO] Model is improving ppl: 3.73099 --> 3.66355.
[2019-10-06 22:00:28,948 INFO] Model is improving acc: 72.4152 --> 72.568.
[2019-10-06 22:00:29,158 INFO] Saving checkpoint /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/model/model_step_6000.pt
[2019-10-06 22:01:59,325 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.train.1.pt
[2019-10-06 22:02:06,032 INFO] number of examples: 421684
[2019-10-06 22:02:12,463 INFO] Step 6100/202000; acc:  72.18; ppl:  3.08; xent: 1.12; lr: 0.00113; 26259/26180 tok/s;   6350 sec
[2019-10-06 22:03:54,639 INFO] Step 6200/202000; acc:  72.52; ppl:  3.03; xent: 1.11; lr: 0.00112; 28372/28235 tok/s;   6452 sec
[2019-10-06 22:05:36,668 INFO] Step 6300/202000; acc:  72.64; ppl:  3.00; xent: 1.10; lr: 0.00111; 28546/28393 tok/s;   6554 sec
[2019-10-06 22:07:18,491 INFO] Step 6400/202000; acc:  72.60; ppl:  3.01; xent: 1.10; lr: 0.00110; 28558/28441 tok/s;   6656 sec
[2019-10-06 22:08:01,191 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.train.0.pt
[2019-10-06 22:08:22,379 INFO] number of examples: 892901
[2019-10-06 22:09:00,191 INFO] Step 6500/202000; acc:  72.86; ppl:  2.97; xent: 1.09; lr: 0.00110; 28752/28642 tok/s;   6758 sec
[2019-10-06 22:09:00,192 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.valid.0.pt
[2019-10-06 22:09:00,223 INFO] number of examples: 5006
[2019-10-06 22:09:07,695 INFO] Validation perplexity: 3.58784
[2019-10-06 22:09:07,695 INFO] Validation accuracy: 72.9032
[2019-10-06 22:09:07,695 INFO] Model is improving ppl: 3.66355 --> 3.58784.
[2019-10-06 22:09:07,695 INFO] Model is improving acc: 72.568 --> 72.9032.
[2019-10-06 22:09:07,904 INFO] Saving checkpoint /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/model/model_step_6500.pt
[2019-10-06 22:10:51,367 INFO] Step 6600/202000; acc:  72.84; ppl:  2.97; xent: 1.09; lr: 0.00109; 26288/26204 tok/s;   6869 sec
[2019-10-06 22:12:33,444 INFO] Step 6700/202000; acc:  73.02; ppl:  2.94; xent: 1.08; lr: 0.00108; 28701/28594 tok/s;   6971 sec
[2019-10-06 22:14:15,484 INFO] Step 6800/202000; acc:  72.99; ppl:  2.94; xent: 1.08; lr: 0.00107; 28751/28584 tok/s;   7073 sec
[2019-10-06 22:15:57,408 INFO] Step 6900/202000; acc:  73.08; ppl:  2.93; xent: 1.07; lr: 0.00106; 28738/28650 tok/s;   7175 sec
[2019-10-06 22:17:39,535 INFO] Step 7000/202000; acc:  73.24; ppl:  2.91; xent: 1.07; lr: 0.00106; 28820/28654 tok/s;   7277 sec
[2019-10-06 22:17:39,536 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.valid.0.pt
[2019-10-06 22:17:39,608 INFO] number of examples: 5006
[2019-10-06 22:17:46,973 INFO] Validation perplexity: 3.56272
[2019-10-06 22:17:46,973 INFO] Validation accuracy: 73.1916
[2019-10-06 22:17:46,973 INFO] Model is improving ppl: 3.58784 --> 3.56272.
[2019-10-06 22:17:46,973 INFO] Model is improving acc: 72.9032 --> 73.1916.
[2019-10-06 22:17:47,182 INFO] Saving checkpoint /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/model/model_step_7000.pt
[2019-10-06 22:19:30,742 INFO] Step 7100/202000; acc:  73.16; ppl:  2.92; xent: 1.07; lr: 0.00105; 26438/26281 tok/s;   7388 sec
[2019-10-06 22:21:07,199 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.train.1.pt
[2019-10-06 22:21:13,151 INFO] Step 7200/202000; acc:  72.97; ppl:  2.94; xent: 1.08; lr: 0.00104; 28475/28344 tok/s;   7491 sec
[2019-10-06 22:21:13,873 INFO] number of examples: 421684
[2019-10-06 22:22:55,173 INFO] Step 7300/202000; acc:  73.26; ppl:  2.90; xent: 1.06; lr: 0.00103; 28345/28305 tok/s;   7593 sec
[2019-10-06 22:24:37,257 INFO] Step 7400/202000; acc:  73.40; ppl:  2.87; xent: 1.05; lr: 0.00103; 28563/28377 tok/s;   7695 sec
[2019-10-06 22:26:19,425 INFO] Step 7500/202000; acc:  73.38; ppl:  2.88; xent: 1.06; lr: 0.00102; 28440/28357 tok/s;   7797 sec
[2019-10-06 22:26:19,426 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.valid.0.pt
[2019-10-06 22:26:19,458 INFO] number of examples: 5006
[2019-10-06 22:26:26,919 INFO] Validation perplexity: 3.52373
[2019-10-06 22:26:26,919 INFO] Validation accuracy: 73.2877
[2019-10-06 22:26:26,919 INFO] Model is improving ppl: 3.56272 --> 3.52373.
[2019-10-06 22:26:26,919 INFO] Model is improving acc: 73.1916 --> 73.2877.
[2019-10-06 22:26:27,130 INFO] Saving checkpoint /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/model/model_step_7500.pt
[2019-10-06 22:27:18,951 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.train.0.pt
[2019-10-06 22:27:39,898 INFO] number of examples: 892901
[2019-10-06 22:28:11,053 INFO] Step 7600/202000; acc:  73.63; ppl:  2.84; xent: 1.04; lr: 0.00101; 26234/26089 tok/s;   7909 sec
[2019-10-06 22:29:52,847 INFO] Step 7700/202000; acc:  73.48; ppl:  2.86; xent: 1.05; lr: 0.00101; 28673/28607 tok/s;   8010 sec
[2019-10-06 22:31:35,246 INFO] Step 7800/202000; acc:  73.76; ppl:  2.82; xent: 1.04; lr: 0.00100; 28632/28508 tok/s;   8113 sec
[2019-10-06 22:33:17,895 INFO] Step 7900/202000; acc:  73.73; ppl:  2.82; xent: 1.04; lr: 0.00099; 28604/28370 tok/s;   8215 sec
[2019-10-06 22:35:00,754 INFO] Step 8000/202000; acc:  73.73; ppl:  2.82; xent: 1.04; lr: 0.00099; 28441/28339 tok/s;   8318 sec
[2019-10-06 22:35:00,754 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.valid.0.pt
[2019-10-06 22:35:00,828 INFO] number of examples: 5006
[2019-10-06 22:35:08,216 INFO] Validation perplexity: 3.47907
[2019-10-06 22:35:08,216 INFO] Validation accuracy: 73.4909
[2019-10-06 22:35:08,216 INFO] Model is improving ppl: 3.52373 --> 3.47907.
[2019-10-06 22:35:08,216 INFO] Model is improving acc: 73.2877 --> 73.4909.
[2019-10-06 22:35:08,425 INFO] Saving checkpoint /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/model/model_step_8000.pt
[2019-10-06 22:36:51,827 INFO] Step 8100/202000; acc:  73.94; ppl:  2.80; xent: 1.03; lr: 0.00098; 26485/26396 tok/s;   8429 sec
[2019-10-06 22:38:33,662 INFO] Step 8200/202000; acc:  73.80; ppl:  2.81; xent: 1.03; lr: 0.00098; 28913/28687 tok/s;   8531 sec
[2019-10-06 22:40:15,988 INFO] Step 8300/202000; acc:  73.64; ppl:  2.82; xent: 1.04; lr: 0.00097; 28528/28477 tok/s;   8634 sec
[2019-10-06 22:40:17,097 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.train.1.pt
[2019-10-06 22:40:27,877 INFO] number of examples: 421684
[2019-10-06 22:41:57,941 INFO] Step 8400/202000; acc:  73.91; ppl:  2.79; xent: 1.03; lr: 0.00096; 28381/28308 tok/s;   8735 sec
[2019-10-06 22:43:39,621 INFO] Step 8500/202000; acc:  74.06; ppl:  2.77; xent: 1.02; lr: 0.00096; 28595/28428 tok/s;   8837 sec
[2019-10-06 22:43:39,622 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.valid.0.pt
[2019-10-06 22:43:39,652 INFO] number of examples: 5006
[2019-10-06 22:43:47,115 INFO] Validation perplexity: 3.4731
[2019-10-06 22:43:47,115 INFO] Validation accuracy: 73.53
[2019-10-06 22:43:47,115 INFO] Model is improving ppl: 3.47907 --> 3.4731.
[2019-10-06 22:43:47,115 INFO] Model is improving acc: 73.4909 --> 73.53.
[2019-10-06 22:43:47,325 INFO] Saving checkpoint /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/model/model_step_8500.pt
[2019-10-06 22:45:30,801 INFO] Step 8600/202000; acc:  73.95; ppl:  2.78; xent: 1.02; lr: 0.00095; 26203/26114 tok/s;   8948 sec
[2019-10-06 22:46:28,425 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.train.0.pt
[2019-10-06 22:46:46,478 INFO] number of examples: 892901
[2019-10-06 22:47:12,952 INFO] Step 8700/202000; acc:  74.23; ppl:  2.75; xent: 1.01; lr: 0.00095; 28618/28393 tok/s;   9050 sec
[2019-10-06 22:48:55,430 INFO] Step 8800/202000; acc:  74.09; ppl:  2.76; xent: 1.01; lr: 0.00094; 28446/28499 tok/s;   9153 sec
[2019-10-06 22:50:37,432 INFO] Step 8900/202000; acc:  74.30; ppl:  2.73; xent: 1.00; lr: 0.00094; 28795/28625 tok/s;   9255 sec
[2019-10-06 22:52:19,568 INFO] Step 9000/202000; acc:  74.24; ppl:  2.74; xent: 1.01; lr: 0.00093; 28691/28484 tok/s;   9357 sec
[2019-10-06 22:52:19,569 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.valid.0.pt
[2019-10-06 22:52:19,601 INFO] number of examples: 5006
[2019-10-06 22:52:27,081 INFO] Validation perplexity: 3.43984
[2019-10-06 22:52:27,082 INFO] Validation accuracy: 73.6594
[2019-10-06 22:52:27,082 INFO] Model is improving ppl: 3.4731 --> 3.43984.
[2019-10-06 22:52:27,082 INFO] Model is improving acc: 73.53 --> 73.6594.
[2019-10-06 22:52:27,292 INFO] Saving checkpoint /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/model/model_step_9000.pt
[2019-10-06 22:54:10,811 INFO] Step 9100/202000; acc:  74.24; ppl:  2.73; xent: 1.01; lr: 0.00093; 26287/26163 tok/s;   9468 sec
[2019-10-06 22:55:53,309 INFO] Step 9200/202000; acc:  74.44; ppl:  2.71; xent: 1.00; lr: 0.00092; 28708/28673 tok/s;   9571 sec
[2019-10-06 22:57:35,635 INFO] Step 9300/202000; acc:  74.37; ppl:  2.72; xent: 1.00; lr: 0.00092; 28793/28569 tok/s;   9673 sec
[2019-10-06 22:59:17,464 INFO] Step 9400/202000; acc:  74.24; ppl:  2.73; xent: 1.00; lr: 0.00091; 28652/28572 tok/s;   9775 sec
[2019-10-06 22:59:25,791 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.train.1.pt
[2019-10-06 22:59:32,682 INFO] number of examples: 421684
[2019-10-06 23:00:59,923 INFO] Step 9500/202000; acc:  74.37; ppl:  2.71; xent: 1.00; lr: 0.00091; 28258/28207 tok/s;   9877 sec
[2019-10-06 23:00:59,924 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.valid.0.pt
[2019-10-06 23:00:59,991 INFO] number of examples: 5006
[2019-10-06 23:01:07,430 INFO] Validation perplexity: 3.41843
[2019-10-06 23:01:07,431 INFO] Validation accuracy: 73.7263
[2019-10-06 23:01:07,431 INFO] Model is improving ppl: 3.43984 --> 3.41843.
[2019-10-06 23:01:07,431 INFO] Model is improving acc: 73.6594 --> 73.7263.
[2019-10-06 23:01:07,641 INFO] Saving checkpoint /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/model/model_step_9500.pt
[2019-10-06 23:02:51,164 INFO] Step 9600/202000; acc:  74.53; ppl:  2.69; xent: 0.99; lr: 0.00090; 26144/25995 tok/s;   9989 sec
[2019-10-06 23:04:33,102 INFO] Step 9700/202000; acc:  74.56; ppl:  2.69; xent: 0.99; lr: 0.00090; 28590/28467 tok/s;  10091 sec
[2019-10-06 23:05:38,520 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.train.0.pt
[2019-10-06 23:05:57,497 INFO] number of examples: 892901
[2019-10-06 23:06:15,257 INFO] Step 9800/202000; acc:  74.65; ppl:  2.68; xent: 0.99; lr: 0.00089; 28607/28348 tok/s;  10193 sec
[2019-10-06 23:07:57,444 INFO] Step 9900/202000; acc:  74.69; ppl:  2.67; xent: 0.98; lr: 0.00089; 28544/28621 tok/s;  10295 sec
[2019-10-06 23:09:39,624 INFO] Step 10000/202000; acc:  74.76; ppl:  2.66; xent: 0.98; lr: 0.00088; 28808/28512 tok/s;  10397 sec
[2019-10-06 23:09:39,625 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.valid.0.pt
[2019-10-06 23:09:39,658 INFO] number of examples: 5006
[2019-10-06 23:09:47,155 INFO] Validation perplexity: 3.4105
[2019-10-06 23:09:47,155 INFO] Validation accuracy: 73.8744
[2019-10-06 23:09:47,155 INFO] Model is improving ppl: 3.41843 --> 3.4105.
[2019-10-06 23:09:47,155 INFO] Model is improving acc: 73.7263 --> 73.8744.
[2019-10-06 23:09:47,365 INFO] Saving checkpoint /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/model/model_step_10000.pt
[2019-10-06 23:11:31,133 INFO] Step 10100/202000; acc:  74.70; ppl:  2.67; xent: 0.98; lr: 0.00088; 26194/26140 tok/s;  10509 sec
[2019-10-06 23:13:13,453 INFO] Step 10200/202000; acc:  74.73; ppl:  2.66; xent: 0.98; lr: 0.00088; 28541/28421 tok/s;  10611 sec
[2019-10-06 23:14:55,664 INFO] Step 10300/202000; acc:  74.97; ppl:  2.63; xent: 0.97; lr: 0.00087; 28829/28772 tok/s;  10713 sec
[2019-10-06 23:16:37,541 INFO] Step 10400/202000; acc:  74.81; ppl:  2.65; xent: 0.98; lr: 0.00087; 28916/28659 tok/s;  10815 sec
[2019-10-06 23:18:19,260 INFO] Step 10500/202000; acc:  74.74; ppl:  2.65; xent: 0.98; lr: 0.00086; 28710/28594 tok/s;  10917 sec
[2019-10-06 23:18:19,261 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.valid.0.pt
[2019-10-06 23:18:19,335 INFO] number of examples: 5006
[2019-10-06 23:18:26,712 INFO] Validation perplexity: 3.38492
[2019-10-06 23:18:26,712 INFO] Validation accuracy: 73.9308
[2019-10-06 23:18:26,712 INFO] Model is improving ppl: 3.4105 --> 3.38492.
[2019-10-06 23:18:26,712 INFO] Model is improving acc: 73.8744 --> 73.9308.
[2019-10-06 23:18:26,921 INFO] Saving checkpoint /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/model/model_step_10500.pt
[2019-10-06 23:18:43,741 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.train.1.pt
[2019-10-06 23:18:54,090 INFO] number of examples: 421684
[2019-10-06 23:20:10,310 INFO] Step 10600/202000; acc:  74.78; ppl:  2.65; xent: 0.98; lr: 0.00086; 26042/26068 tok/s;  11028 sec
[2019-10-06 23:21:52,485 INFO] Step 10700/202000; acc:  75.02; ppl:  2.62; xent: 0.96; lr: 0.00085; 28490/28331 tok/s;  11130 sec
[2019-10-06 23:23:34,783 INFO] Step 10800/202000; acc:  75.10; ppl:  2.62; xent: 0.96; lr: 0.00085; 28514/28314 tok/s;  11232 sec
[2019-10-06 23:24:47,120 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.train.0.pt
[2019-10-06 23:25:04,109 INFO] number of examples: 892901
[2019-10-06 23:25:16,518 INFO] Step 10900/202000; acc:  74.98; ppl:  2.63; xent: 0.97; lr: 0.00085; 28676/28507 tok/s;  11334 sec
[2019-10-06 23:26:58,747 INFO] Step 11000/202000; acc:  75.11; ppl:  2.61; xent: 0.96; lr: 0.00084; 28547/28552 tok/s;  11436 sec
[2019-10-06 23:26:58,748 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.valid.0.pt
[2019-10-06 23:26:58,784 INFO] number of examples: 5006
[2019-10-06 23:27:06,229 INFO] Validation perplexity: 3.37365
[2019-10-06 23:27:06,229 INFO] Validation accuracy: 74.007
[2019-10-06 23:27:06,229 INFO] Model is improving ppl: 3.38492 --> 3.37365.
[2019-10-06 23:27:06,229 INFO] Model is improving acc: 73.9308 --> 74.007.
[2019-10-06 23:27:06,438 INFO] Saving checkpoint /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/model/model_step_11000.pt
[2019-10-06 23:28:50,053 INFO] Step 11100/202000; acc:  75.09; ppl:  2.61; xent: 0.96; lr: 0.00084; 26427/26176 tok/s;  11548 sec
[2019-10-06 23:30:32,500 INFO] Step 11200/202000; acc:  75.19; ppl:  2.60; xent: 0.96; lr: 0.00084; 28503/28438 tok/s;  11650 sec
[2019-10-06 23:32:14,823 INFO] Step 11300/202000; acc:  75.24; ppl:  2.59; xent: 0.95; lr: 0.00083; 28582/28438 tok/s;  11752 sec
[2019-10-06 23:33:57,920 INFO] Step 11400/202000; acc:  75.33; ppl:  2.58; xent: 0.95; lr: 0.00083; 28585/28535 tok/s;  11855 sec
[2019-10-06 23:35:40,298 INFO] Step 11500/202000; acc:  75.22; ppl:  2.59; xent: 0.95; lr: 0.00082; 28757/28494 tok/s;  11958 sec
[2019-10-06 23:35:40,298 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.valid.0.pt
[2019-10-06 23:35:40,380 INFO] number of examples: 5006
[2019-10-06 23:35:47,763 INFO] Validation perplexity: 3.36747
[2019-10-06 23:35:47,763 INFO] Validation accuracy: 74.0482
[2019-10-06 23:35:47,763 INFO] Model is improving ppl: 3.37365 --> 3.36747.
[2019-10-06 23:35:47,763 INFO] Model is improving acc: 74.007 --> 74.0482.
[2019-10-06 23:35:47,972 INFO] Saving checkpoint /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/model/model_step_11500.pt
[2019-10-06 23:37:31,544 INFO] Step 11600/202000; acc:  75.13; ppl:  2.60; xent: 0.96; lr: 0.00082; 26257/26208 tok/s;  12069 sec
[2019-10-06 23:37:54,210 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.train.1.pt
[2019-10-06 23:38:04,414 INFO] number of examples: 421684
[2019-10-06 23:39:13,673 INFO] Step 11700/202000; acc:  75.15; ppl:  2.60; xent: 0.95; lr: 0.00082; 28322/28294 tok/s;  12171 sec
[2019-10-06 23:40:56,151 INFO] Step 11800/202000; acc:  75.48; ppl:  2.56; xent: 0.94; lr: 0.00081; 28392/28263 tok/s;  12274 sec
[2019-10-06 23:42:38,174 INFO] Step 11900/202000; acc:  75.41; ppl:  2.57; xent: 0.94; lr: 0.00081; 28590/28357 tok/s;  12376 sec
[2019-10-06 23:43:58,142 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.train.0.pt
[2019-10-06 23:44:18,021 INFO] number of examples: 892901
[2019-10-06 23:44:20,518 INFO] Step 12000/202000; acc:  75.41; ppl:  2.57; xent: 0.94; lr: 0.00081; 28521/28390 tok/s;  12478 sec
[2019-10-06 23:44:20,519 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.valid.0.pt
[2019-10-06 23:44:20,551 INFO] number of examples: 5006
[2019-10-06 23:44:28,050 INFO] Validation perplexity: 3.36421
[2019-10-06 23:44:28,051 INFO] Validation accuracy: 74.1218
[2019-10-06 23:44:28,051 INFO] Model is improving ppl: 3.36747 --> 3.36421.
[2019-10-06 23:44:28,051 INFO] Model is improving acc: 74.0482 --> 74.1218.
[2019-10-06 23:44:28,260 INFO] Saving checkpoint /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/model/model_step_12000.pt
[2019-10-06 23:46:11,254 INFO] Step 12100/202000; acc:  75.46; ppl:  2.56; xent: 0.94; lr: 0.00080; 26407/26379 tok/s;  12589 sec
[2019-10-06 23:47:53,832 INFO] Step 12200/202000; acc:  75.49; ppl:  2.55; xent: 0.94; lr: 0.00080; 28577/28335 tok/s;  12691 sec
[2019-10-06 23:49:36,246 INFO] Step 12300/202000; acc:  75.51; ppl:  2.55; xent: 0.94; lr: 0.00080; 28529/28483 tok/s;  12794 sec
[2019-10-06 23:51:18,755 INFO] Step 12400/202000; acc:  75.61; ppl:  2.54; xent: 0.93; lr: 0.00079; 28534/28380 tok/s;  12896 sec
[2019-10-06 23:53:00,845 INFO] Step 12500/202000; acc:  75.73; ppl:  2.53; xent: 0.93; lr: 0.00079; 28848/28780 tok/s;  12998 sec
[2019-10-06 23:53:00,846 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.valid.0.pt
[2019-10-06 23:53:00,879 INFO] number of examples: 5006
[2019-10-06 23:53:08,372 INFO] Validation perplexity: 3.33944
[2019-10-06 23:53:08,372 INFO] Validation accuracy: 74.1554
[2019-10-06 23:53:08,372 INFO] Model is improving ppl: 3.36421 --> 3.33944.
[2019-10-06 23:53:08,372 INFO] Model is improving acc: 74.1218 --> 74.1554.
[2019-10-06 23:53:08,584 INFO] Saving checkpoint /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/model/model_step_12500.pt
[2019-10-06 23:54:52,462 INFO] Step 12600/202000; acc:  75.55; ppl:  2.55; xent: 0.93; lr: 0.00079; 26358/26169 tok/s;  13110 sec
[2019-10-06 23:56:34,840 INFO] Step 12700/202000; acc:  75.49; ppl:  2.55; xent: 0.94; lr: 0.00078; 28545/28449 tok/s;  13212 sec
[2019-10-06 23:57:05,802 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.train.1.pt
[2019-10-06 23:57:12,602 INFO] number of examples: 421684
[2019-10-06 23:58:17,762 INFO] Step 12800/202000; acc:  75.60; ppl:  2.54; xent: 0.93; lr: 0.00078; 28257/28115 tok/s;  13315 sec
[2019-10-06 23:59:59,777 INFO] Step 12900/202000; acc:  75.75; ppl:  2.52; xent: 0.92; lr: 0.00078; 28383/28343 tok/s;  13417 sec
[2019-10-07 00:01:42,147 INFO] Step 13000/202000; acc:  75.81; ppl:  2.51; xent: 0.92; lr: 0.00078; 28486/28253 tok/s;  13520 sec
[2019-10-07 00:01:42,148 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.valid.0.pt
[2019-10-07 00:01:42,216 INFO] number of examples: 5006
[2019-10-07 00:01:49,658 INFO] Validation perplexity: 3.3371
[2019-10-07 00:01:49,658 INFO] Validation accuracy: 74.2173
[2019-10-07 00:01:49,658 INFO] Model is improving ppl: 3.33944 --> 3.3371.
[2019-10-07 00:01:49,658 INFO] Model is improving acc: 74.1554 --> 74.2173.
[2019-10-07 00:01:49,869 INFO] Saving checkpoint /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/model/model_step_13000.pt
[2019-10-07 00:03:18,053 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.train.0.pt
[2019-10-07 00:03:33,189 INFO] Step 13100/202000; acc:  75.73; ppl:  2.52; xent: 0.92; lr: 0.00077; 26341/26205 tok/s;  13631 sec
[2019-10-07 00:03:36,695 INFO] number of examples: 892901
[2019-10-07 00:05:15,303 INFO] Step 13200/202000; acc:  75.82; ppl:  2.51; xent: 0.92; lr: 0.00077; 28572/28602 tok/s;  13733 sec
[2019-10-07 00:06:57,937 INFO] Step 13300/202000; acc:  75.86; ppl:  2.50; xent: 0.92; lr: 0.00077; 28580/28323 tok/s;  13835 sec
[2019-10-07 00:08:40,777 INFO] Step 13400/202000; acc:  75.89; ppl:  2.50; xent: 0.92; lr: 0.00076; 28488/28324 tok/s;  13938 sec
[2019-10-07 00:10:22,946 INFO] Step 13500/202000; acc:  75.88; ppl:  2.50; xent: 0.92; lr: 0.00076; 28579/28463 tok/s;  14040 sec
[2019-10-07 00:10:22,946 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.valid.0.pt
[2019-10-07 00:10:22,978 INFO] number of examples: 5006
[2019-10-07 00:10:30,443 INFO] Validation perplexity: 3.33663
[2019-10-07 00:10:30,443 INFO] Validation accuracy: 74.2163
[2019-10-07 00:10:30,443 INFO] Stalled patience: 4/5
[2019-10-07 00:10:30,653 INFO] Saving checkpoint /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/model/model_step_13500.pt
[2019-10-07 00:12:14,911 INFO] Step 13600/202000; acc:  76.08; ppl:  2.48; xent: 0.91; lr: 0.00076; 26295/26300 tok/s;  14152 sec
[2019-10-07 00:13:56,930 INFO] Step 13700/202000; acc:  75.86; ppl:  2.50; xent: 0.92; lr: 0.00076; 28824/28602 tok/s;  14254 sec
[2019-10-07 00:15:38,822 INFO] Step 13800/202000; acc:  75.77; ppl:  2.51; xent: 0.92; lr: 0.00075; 28654/28582 tok/s;  14356 sec
[2019-10-07 00:16:16,665 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.train.1.pt
[2019-10-07 00:16:26,722 INFO] number of examples: 421684
[2019-10-07 00:17:21,080 INFO] Step 13900/202000; acc:  75.94; ppl:  2.49; xent: 0.91; lr: 0.00075; 28474/28335 tok/s;  14459 sec
[2019-10-07 00:19:03,171 INFO] Step 14000/202000; acc:  76.00; ppl:  2.48; xent: 0.91; lr: 0.00075; 28379/28291 tok/s;  14561 sec
[2019-10-07 00:19:03,171 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.valid.0.pt
[2019-10-07 00:19:03,247 INFO] number of examples: 5006
[2019-10-07 00:19:10,709 INFO] Validation perplexity: 3.33802
[2019-10-07 00:19:10,709 INFO] Validation accuracy: 74.2756
[2019-10-07 00:19:10,709 INFO] Stalled patience: 3/5
[2019-10-07 00:19:10,919 INFO] Saving checkpoint /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/model/model_step_14000.pt
[2019-10-07 00:20:54,455 INFO] Step 14100/202000; acc:  76.09; ppl:  2.48; xent: 0.91; lr: 0.00074; 26232/26051 tok/s;  14672 sec
[2019-10-07 00:22:28,980 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.train.0.pt
[2019-10-07 00:22:37,031 INFO] Step 14200/202000; acc:  76.19; ppl:  2.47; xent: 0.90; lr: 0.00074; 28487/28322 tok/s;  14775 sec
[2019-10-07 00:22:48,151 INFO] number of examples: 892901
[2019-10-07 00:24:19,653 INFO] Step 14300/202000; acc:  76.02; ppl:  2.48; xent: 0.91; lr: 0.00074; 28453/28426 tok/s;  14877 sec
[2019-10-07 00:26:02,170 INFO] Step 14400/202000; acc:  76.18; ppl:  2.46; xent: 0.90; lr: 0.00074; 28601/28325 tok/s;  14980 sec
[2019-10-07 00:27:44,866 INFO] Step 14500/202000; acc:  76.16; ppl:  2.46; xent: 0.90; lr: 0.00073; 28510/28516 tok/s;  15082 sec
[2019-10-07 00:27:44,867 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.valid.0.pt
[2019-10-07 00:27:44,901 INFO] number of examples: 5006
[2019-10-07 00:27:52,379 INFO] Validation perplexity: 3.31699
[2019-10-07 00:27:52,379 INFO] Validation accuracy: 74.4156
[2019-10-07 00:27:52,379 INFO] Model is improving ppl: 3.3371 --> 3.31699.
[2019-10-07 00:27:52,379 INFO] Model is improving acc: 74.2173 --> 74.4156.
[2019-10-07 00:27:52,590 INFO] Saving checkpoint /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/model/model_step_14500.pt
[2019-10-07 00:29:36,394 INFO] Step 14600/202000; acc:  76.14; ppl:  2.47; xent: 0.90; lr: 0.00073; 26211/26031 tok/s;  15194 sec
[2019-10-07 00:31:18,941 INFO] Step 14700/202000; acc:  76.39; ppl:  2.44; xent: 0.89; lr: 0.00073; 28672/28659 tok/s;  15296 sec
[2019-10-07 00:33:00,981 INFO] Step 14800/202000; acc:  76.14; ppl:  2.47; xent: 0.90; lr: 0.00073; 28793/28564 tok/s;  15399 sec
[2019-10-07 00:34:43,180 INFO] Step 14900/202000; acc:  76.11; ppl:  2.47; xent: 0.90; lr: 0.00072; 28586/28587 tok/s;  15501 sec
[2019-10-07 00:35:28,820 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.train.1.pt
[2019-10-07 00:35:39,440 INFO] number of examples: 421684
[2019-10-07 00:36:26,143 INFO] Step 15000/202000; acc:  76.26; ppl:  2.45; xent: 0.90; lr: 0.00072; 28318/28117 tok/s;  15604 sec
[2019-10-07 00:36:26,143 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.valid.0.pt
[2019-10-07 00:36:26,225 INFO] number of examples: 5006
[2019-10-07 00:36:33,600 INFO] Validation perplexity: 3.33732
[2019-10-07 00:36:33,600 INFO] Validation accuracy: 74.3881
[2019-10-07 00:36:33,600 INFO] Decreasing patience: 4/5
[2019-10-07 00:36:33,810 INFO] Saving checkpoint /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/model/model_step_15000.pt
[2019-10-07 00:38:17,314 INFO] Step 15100/202000; acc:  76.28; ppl:  2.45; xent: 0.90; lr: 0.00072; 26052/25956 tok/s;  15715 sec
[2019-10-07 00:39:58,956 INFO] Step 15200/202000; acc:  76.41; ppl:  2.44; xent: 0.89; lr: 0.00072; 28760/28563 tok/s;  15817 sec
[2019-10-07 00:41:40,280 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.train.0.pt
[2019-10-07 00:41:41,251 INFO] Step 15300/202000; acc:  76.42; ppl:  2.43; xent: 0.89; lr: 0.00071; 28507/28324 tok/s;  15919 sec
[2019-10-07 00:41:58,080 INFO] number of examples: 892901
[2019-10-07 00:43:23,216 INFO] Step 15400/202000; acc:  76.40; ppl:  2.44; xent: 0.89; lr: 0.00071; 28654/28568 tok/s;  16021 sec
[2019-10-07 00:45:06,255 INFO] Step 15500/202000; acc:  76.42; ppl:  2.43; xent: 0.89; lr: 0.00071; 28430/28293 tok/s;  16124 sec
[2019-10-07 00:45:06,256 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.valid.0.pt
[2019-10-07 00:45:06,287 INFO] number of examples: 5006
[2019-10-07 00:45:13,746 INFO] Validation perplexity: 3.32067
[2019-10-07 00:45:13,746 INFO] Validation accuracy: 74.2988
[2019-10-07 00:45:13,746 INFO] Decreasing patience: 3/5
[2019-10-07 00:45:13,956 INFO] Saving checkpoint /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/model/model_step_15500.pt
[2019-10-07 00:46:57,853 INFO] Step 15600/202000; acc:  76.51; ppl:  2.42; xent: 0.88; lr: 0.00071; 26206/26207 tok/s;  16235 sec
[2019-10-07 00:48:39,929 INFO] Step 15700/202000; acc:  76.39; ppl:  2.44; xent: 0.89; lr: 0.00071; 28681/28461 tok/s;  16337 sec
[2019-10-07 00:50:22,126 INFO] Step 15800/202000; acc:  76.70; ppl:  2.41; xent: 0.88; lr: 0.00070; 28740/28741 tok/s;  16440 sec
[2019-10-07 00:52:04,524 INFO] Step 15900/202000; acc:  76.47; ppl:  2.43; xent: 0.89; lr: 0.00070; 28744/28581 tok/s;  16542 sec
[2019-10-07 00:53:47,318 INFO] Step 16000/202000; acc:  76.42; ppl:  2.43; xent: 0.89; lr: 0.00070; 28486/28359 tok/s;  16645 sec
[2019-10-07 00:53:47,319 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.valid.0.pt
[2019-10-07 00:53:47,352 INFO] number of examples: 5006
[2019-10-07 00:53:54,797 INFO] Validation perplexity: 3.32847
[2019-10-07 00:53:54,798 INFO] Validation accuracy: 74.3131
[2019-10-07 00:53:54,798 INFO] Decreasing patience: 2/5
[2019-10-07 00:53:55,008 INFO] Saving checkpoint /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/model/model_step_16000.pt
[2019-10-07 00:54:48,845 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.train.1.pt
[2019-10-07 00:54:55,532 INFO] number of examples: 421684
[2019-10-07 00:55:38,707 INFO] Step 16100/202000; acc:  76.55; ppl:  2.41; xent: 0.88; lr: 0.00070; 26127/25936 tok/s;  16756 sec
[2019-10-07 00:57:20,841 INFO] Step 16200/202000; acc:  76.49; ppl:  2.42; xent: 0.88; lr: 0.00069; 28380/28247 tok/s;  16858 sec
[2019-10-07 00:59:03,120 INFO] Step 16300/202000; acc:  76.70; ppl:  2.40; xent: 0.87; lr: 0.00069; 28580/28456 tok/s;  16961 sec
[2019-10-07 01:00:45,270 INFO] Step 16400/202000; acc:  76.63; ppl:  2.41; xent: 0.88; lr: 0.00069; 28485/28287 tok/s;  17063 sec
[2019-10-07 01:00:51,543 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.train.0.pt
[2019-10-07 01:01:12,819 INFO] number of examples: 892901
[2019-10-07 01:02:27,395 INFO] Step 16500/202000; acc:  76.70; ppl:  2.40; xent: 0.88; lr: 0.00069; 28631/28610 tok/s;  17165 sec
[2019-10-07 01:02:27,395 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.valid.0.pt
[2019-10-07 01:02:27,466 INFO] number of examples: 5006
[2019-10-07 01:02:34,892 INFO] Validation perplexity: 3.31841
[2019-10-07 01:02:34,892 INFO] Validation accuracy: 74.4453
[2019-10-07 01:02:34,892 INFO] Stalled patience: 4/5
[2019-10-07 01:02:35,101 INFO] Saving checkpoint /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/model/model_step_16500.pt
[2019-10-07 01:04:18,326 INFO] Step 16600/202000; acc:  76.70; ppl:  2.40; xent: 0.88; lr: 0.00069; 26405/26229 tok/s;  17276 sec
[2019-10-07 01:06:01,156 INFO] Step 16700/202000; acc:  76.72; ppl:  2.40; xent: 0.87; lr: 0.00068; 28395/28405 tok/s;  17379 sec
[2019-10-07 01:07:43,804 INFO] Step 16800/202000; acc:  76.64; ppl:  2.40; xent: 0.88; lr: 0.00068; 28557/28320 tok/s;  17481 sec
[2019-10-07 01:09:25,803 INFO] Step 16900/202000; acc:  76.92; ppl:  2.38; xent: 0.87; lr: 0.00068; 28785/28741 tok/s;  17583 sec
[2019-10-07 01:11:08,274 INFO] Step 17000/202000; acc:  76.73; ppl:  2.40; xent: 0.87; lr: 0.00068; 28724/28638 tok/s;  17686 sec
[2019-10-07 01:11:08,275 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.valid.0.pt
[2019-10-07 01:11:08,306 INFO] number of examples: 5006
[2019-10-07 01:11:15,771 INFO] Validation perplexity: 3.32448
[2019-10-07 01:11:15,771 INFO] Validation accuracy: 74.4235
[2019-10-07 01:11:15,771 INFO] Stalled patience: 3/5
[2019-10-07 01:11:15,981 INFO] Saving checkpoint /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/model/model_step_17000.pt
[2019-10-07 01:12:59,364 INFO] Step 17100/202000; acc:  76.70; ppl:  2.40; xent: 0.88; lr: 0.00068; 26367/26227 tok/s;  17797 sec
[2019-10-07 01:13:58,978 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.train.1.pt
[2019-10-07 01:14:05,728 INFO] number of examples: 421684
[2019-10-07 01:14:41,864 INFO] Step 17200/202000; acc:  76.77; ppl:  2.39; xent: 0.87; lr: 0.00067; 28417/28224 tok/s;  17899 sec
[2019-10-07 01:16:24,313 INFO] Step 17300/202000; acc:  76.74; ppl:  2.39; xent: 0.87; lr: 0.00067; 28237/28060 tok/s;  18002 sec
[2019-10-07 01:18:06,450 INFO] Step 17400/202000; acc:  76.97; ppl:  2.37; xent: 0.86; lr: 0.00067; 28639/28526 tok/s;  18104 sec
[2019-10-07 01:19:48,995 INFO] Step 17500/202000; acc:  76.90; ppl:  2.38; xent: 0.87; lr: 0.00067; 28364/28218 tok/s;  18207 sec
[2019-10-07 01:19:48,995 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.valid.0.pt
[2019-10-07 01:19:49,069 INFO] number of examples: 5006
[2019-10-07 01:19:56,536 INFO] Validation perplexity: 3.31393
[2019-10-07 01:19:56,536 INFO] Validation accuracy: 74.4372
[2019-10-07 01:19:56,536 INFO] Model is improving ppl: 3.31699 --> 3.31393.
[2019-10-07 01:19:56,536 INFO] Model is improving acc: 74.4156 --> 74.4372.
[2019-10-07 01:19:56,744 INFO] Saving checkpoint /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/model/model_step_17500.pt
[2019-10-07 01:20:11,563 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.train.0.pt
[2019-10-07 01:20:29,646 INFO] number of examples: 892901
[2019-10-07 01:21:40,521 INFO] Step 17600/202000; acc:  77.01; ppl:  2.37; xent: 0.86; lr: 0.00067; 26257/26150 tok/s;  18318 sec
[2019-10-07 01:23:23,008 INFO] Step 17700/202000; acc:  76.93; ppl:  2.37; xent: 0.86; lr: 0.00066; 28536/28379 tok/s;  18421 sec
[2019-10-07 01:25:05,975 INFO] Step 17800/202000; acc:  76.97; ppl:  2.36; xent: 0.86; lr: 0.00066; 28391/28379 tok/s;  18524 sec
[2019-10-07 01:26:48,594 INFO] Step 17900/202000; acc:  76.91; ppl:  2.37; xent: 0.86; lr: 0.00066; 28555/28394 tok/s;  18626 sec
[2019-10-07 01:28:30,933 INFO] Step 18000/202000; acc:  77.13; ppl:  2.35; xent: 0.86; lr: 0.00066; 28712/28604 tok/s;  18728 sec
[2019-10-07 01:28:30,934 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.valid.0.pt
[2019-10-07 01:28:30,966 INFO] number of examples: 5006
[2019-10-07 01:28:38,399 INFO] Validation perplexity: 3.31869
[2019-10-07 01:28:38,400 INFO] Validation accuracy: 74.4415
[2019-10-07 01:28:38,400 INFO] Stalled patience: 4/5
[2019-10-07 01:28:38,615 INFO] Saving checkpoint /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/model/model_step_18000.pt
[2019-10-07 01:30:22,615 INFO] Step 18100/202000; acc:  76.96; ppl:  2.37; xent: 0.86; lr: 0.00066; 26314/26265 tok/s;  18840 sec
[2019-10-07 01:32:04,793 INFO] Step 18200/202000; acc:  76.89; ppl:  2.37; xent: 0.86; lr: 0.00066; 28693/28581 tok/s;  18942 sec
[2019-10-07 01:33:11,419 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.train.1.pt
[2019-10-07 01:33:21,120 INFO] number of examples: 421684
[2019-10-07 01:33:47,368 INFO] Step 18300/202000; acc:  77.07; ppl:  2.36; xent: 0.86; lr: 0.00065; 28375/28157 tok/s;  19045 sec
[2019-10-07 01:35:29,820 INFO] Step 18400/202000; acc:  76.99; ppl:  2.36; xent: 0.86; lr: 0.00065; 28287/28081 tok/s;  19147 sec
[2019-10-07 01:37:12,223 INFO] Step 18500/202000; acc:  77.19; ppl:  2.34; xent: 0.85; lr: 0.00065; 28565/28396 tok/s;  19250 sec
[2019-10-07 01:37:12,224 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.valid.0.pt
[2019-10-07 01:37:12,298 INFO] number of examples: 5006
[2019-10-07 01:37:19,507 INFO] Validation perplexity: 3.32156
[2019-10-07 01:37:19,507 INFO] Validation accuracy: 74.3983
[2019-10-07 01:37:19,507 INFO] Decreasing patience: 4/5
[2019-10-07 01:37:19,716 INFO] Saving checkpoint /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/model/model_step_18500.pt
[2019-10-07 01:39:03,783 INFO] Step 18600/202000; acc:  77.07; ppl:  2.36; xent: 0.86; lr: 0.00065; 26081/25990 tok/s;  19361 sec
[2019-10-07 01:39:25,493 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.train.0.pt
[2019-10-07 01:39:51,061 INFO] number of examples: 892901
[2019-10-07 01:40:46,188 INFO] Step 18700/202000; acc:  77.17; ppl:  2.34; xent: 0.85; lr: 0.00065; 28564/28487 tok/s;  19464 sec
[2019-10-07 01:42:28,225 INFO] Step 18800/202000; acc:  77.18; ppl:  2.35; xent: 0.85; lr: 0.00064; 28624/28460 tok/s;  19566 sec
[2019-10-07 01:44:10,639 INFO] Step 18900/202000; acc:  77.22; ppl:  2.34; xent: 0.85; lr: 0.00064; 28559/28524 tok/s;  19668 sec
[2019-10-07 01:45:53,068 INFO] Step 19000/202000; acc:  77.21; ppl:  2.34; xent: 0.85; lr: 0.00064; 28610/28502 tok/s;  19771 sec
[2019-10-07 01:45:53,068 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.valid.0.pt
[2019-10-07 01:45:53,101 INFO] number of examples: 5006
[2019-10-07 01:46:00,607 INFO] Validation perplexity: 3.30948
[2019-10-07 01:46:00,608 INFO] Validation accuracy: 74.4835
[2019-10-07 01:46:00,608 INFO] Model is improving ppl: 3.31393 --> 3.30948.
[2019-10-07 01:46:00,608 INFO] Model is improving acc: 74.4372 --> 74.4835.
[2019-10-07 01:46:00,817 INFO] Saving checkpoint /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/model/model_step_19000.pt
[2019-10-07 01:47:44,630 INFO] Step 19100/202000; acc:  77.26; ppl:  2.33; xent: 0.85; lr: 0.00064; 26323/26189 tok/s;  19882 sec
[2019-10-07 01:49:26,841 INFO] Step 19200/202000; acc:  77.28; ppl:  2.34; xent: 0.85; lr: 0.00064; 28778/28676 tok/s;  19984 sec
[2019-10-07 01:51:09,036 INFO] Step 19300/202000; acc:  77.12; ppl:  2.35; xent: 0.85; lr: 0.00064; 28712/28580 tok/s;  20087 sec
[2019-10-07 01:52:22,828 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.train.1.pt
[2019-10-07 01:52:33,354 INFO] number of examples: 421684
[2019-10-07 01:52:51,241 INFO] Step 19400/202000; acc:  77.16; ppl:  2.34; xent: 0.85; lr: 0.00063; 28459/28315 tok/s;  20189 sec
[2019-10-07 01:54:34,019 INFO] Step 19500/202000; acc:  77.29; ppl:  2.33; xent: 0.84; lr: 0.00063; 28225/27988 tok/s;  20292 sec
[2019-10-07 01:54:34,020 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.valid.0.pt
[2019-10-07 01:54:34,053 INFO] number of examples: 5006
[2019-10-07 01:54:41,542 INFO] Validation perplexity: 3.3317
[2019-10-07 01:54:41,542 INFO] Validation accuracy: 74.4068
[2019-10-07 01:54:41,542 INFO] Decreasing patience: 4/5
[2019-10-07 01:54:41,752 INFO] Saving checkpoint /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/model/model_step_19500.pt
[2019-10-07 01:56:25,533 INFO] Step 19600/202000; acc:  77.40; ppl:  2.32; xent: 0.84; lr: 0.00063; 26184/26056 tok/s;  20403 sec
[2019-10-07 01:58:07,774 INFO] Step 19700/202000; acc:  77.31; ppl:  2.33; xent: 0.85; lr: 0.00063; 28453/28365 tok/s;  20505 sec
[2019-10-07 01:58:36,466 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.train.0.pt
[2019-10-07 01:58:54,012 INFO] number of examples: 892901
[2019-10-07 01:59:49,778 INFO] Step 19800/202000; acc:  77.37; ppl:  2.32; xent: 0.84; lr: 0.00063; 28654/28610 tok/s;  20607 sec
[2019-10-07 02:01:32,493 INFO] Step 19900/202000; acc:  77.47; ppl:  2.31; xent: 0.84; lr: 0.00063; 28489/28273 tok/s;  20710 sec
[2019-10-07 02:03:14,734 INFO] Step 20000/202000; acc:  77.37; ppl:  2.32; xent: 0.84; lr: 0.00062; 28624/28617 tok/s;  20812 sec
[2019-10-07 02:03:14,735 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.valid.0.pt
[2019-10-07 02:03:14,804 INFO] number of examples: 5006
[2019-10-07 02:03:22,271 INFO] Validation perplexity: 3.32015
[2019-10-07 02:03:22,271 INFO] Validation accuracy: 74.5152
[2019-10-07 02:03:22,271 INFO] Stalled patience: 4/5
[2019-10-07 02:03:22,482 INFO] Saving checkpoint /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/model/model_step_20000.pt
[2019-10-07 02:05:06,262 INFO] Step 20100/202000; acc:  77.45; ppl:  2.31; xent: 0.84; lr: 0.00062; 26298/26110 tok/s;  20924 sec
[2019-10-07 02:06:48,643 INFO] Step 20200/202000; acc:  77.42; ppl:  2.31; xent: 0.84; lr: 0.00062; 28613/28581 tok/s;  21026 sec
[2019-10-07 02:08:31,315 INFO] Step 20300/202000; acc:  77.50; ppl:  2.31; xent: 0.84; lr: 0.00062; 28655/28485 tok/s;  21129 sec
[2019-10-07 02:10:13,929 INFO] Step 20400/202000; acc:  77.36; ppl:  2.32; xent: 0.84; lr: 0.00062; 28625/28506 tok/s;  21231 sec
[2019-10-07 02:11:34,936 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.train.1.pt
[2019-10-07 02:11:45,712 INFO] number of examples: 421684
[2019-10-07 02:11:56,355 INFO] Step 20500/202000; acc:  77.30; ppl:  2.32; xent: 0.84; lr: 0.00062; 28393/28282 tok/s;  21334 sec
[2019-10-07 02:11:56,356 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.valid.0.pt
[2019-10-07 02:11:56,389 INFO] number of examples: 5006
[2019-10-07 02:12:03,831 INFO] Validation perplexity: 3.3298
[2019-10-07 02:12:03,831 INFO] Validation accuracy: 74.4608
[2019-10-07 02:12:03,831 INFO] Decreasing patience: 3/5
[2019-10-07 02:12:04,040 INFO] Saving checkpoint /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/model/model_step_20500.pt
[2019-10-07 02:13:47,972 INFO] Step 20600/202000; acc:  77.54; ppl:  2.30; xent: 0.83; lr: 0.00062; 26002/25822 tok/s;  21446 sec
[2019-10-07 02:15:30,070 INFO] Step 20700/202000; acc:  77.61; ppl:  2.29; xent: 0.83; lr: 0.00061; 28578/28394 tok/s;  21548 sec
[2019-10-07 02:17:12,448 INFO] Step 20800/202000; acc:  77.49; ppl:  2.31; xent: 0.84; lr: 0.00061; 28361/28335 tok/s;  21650 sec
[2019-10-07 02:17:48,245 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.train.0.pt
[2019-10-07 02:18:06,356 INFO] number of examples: 892901
[2019-10-07 02:18:54,714 INFO] Step 20900/202000; acc:  77.58; ppl:  2.30; xent: 0.83; lr: 0.00061; 28632/28464 tok/s;  21752 sec
[2019-10-07 02:20:36,985 INFO] Step 21000/202000; acc:  77.64; ppl:  2.29; xent: 0.83; lr: 0.00061; 28608/28470 tok/s;  21855 sec
[2019-10-07 02:20:36,986 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.valid.0.pt
[2019-10-07 02:20:37,057 INFO] number of examples: 5006
[2019-10-07 02:20:44,454 INFO] Validation perplexity: 3.32278
[2019-10-07 02:20:44,455 INFO] Validation accuracy: 74.4136
[2019-10-07 02:20:44,455 INFO] Decreasing patience: 2/5
[2019-10-07 02:20:44,665 INFO] Saving checkpoint /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/model/model_step_21000.pt
[2019-10-07 02:22:28,287 INFO] Step 21100/202000; acc:  77.63; ppl:  2.29; xent: 0.83; lr: 0.00061; 26278/26257 tok/s;  21966 sec
[2019-10-07 02:24:10,703 INFO] Step 21200/202000; acc:  77.63; ppl:  2.29; xent: 0.83; lr: 0.00061; 28652/28470 tok/s;  22068 sec
[2019-10-07 02:25:53,748 INFO] Step 21300/202000; acc:  77.61; ppl:  2.29; xent: 0.83; lr: 0.00061; 28423/28358 tok/s;  22171 sec
[2019-10-07 02:27:35,572 INFO] Step 21400/202000; acc:  77.74; ppl:  2.28; xent: 0.83; lr: 0.00060; 28924/28720 tok/s;  22273 sec
[2019-10-07 02:29:17,926 INFO] Step 21500/202000; acc:  77.64; ppl:  2.29; xent: 0.83; lr: 0.00060; 28682/28529 tok/s;  22375 sec
[2019-10-07 02:29:17,926 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.valid.0.pt
[2019-10-07 02:29:17,959 INFO] number of examples: 5006
[2019-10-07 02:29:25,351 INFO] Validation perplexity: 3.32667
[2019-10-07 02:29:25,351 INFO] Validation accuracy: 74.3308
[2019-10-07 02:29:25,351 INFO] Decreasing patience: 1/5
[2019-10-07 02:29:25,560 INFO] Saving checkpoint /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/model/model_step_21500.pt
[2019-10-07 02:30:55,888 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.train.1.pt
[2019-10-07 02:31:02,747 INFO] number of examples: 421684
[2019-10-07 02:31:09,142 INFO] Step 21600/202000; acc:  77.49; ppl:  2.30; xent: 0.84; lr: 0.00060; 26202/26121 tok/s;  22487 sec
[2019-10-07 02:32:51,689 INFO] Step 21700/202000; acc:  77.73; ppl:  2.28; xent: 0.82; lr: 0.00060; 28268/28147 tok/s;  22589 sec
[2019-10-07 02:34:33,996 INFO] Step 21800/202000; acc:  77.77; ppl:  2.28; xent: 0.82; lr: 0.00060; 28463/28316 tok/s;  22692 sec
[2019-10-07 02:36:16,032 INFO] Step 21900/202000; acc:  77.69; ppl:  2.29; xent: 0.83; lr: 0.00060; 28503/28381 tok/s;  22794 sec
[2019-10-07 02:36:58,964 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.train.0.pt
[2019-10-07 02:37:18,505 INFO] number of examples: 892901
[2019-10-07 02:37:58,451 INFO] Step 22000/202000; acc:  77.81; ppl:  2.27; xent: 0.82; lr: 0.00060; 28553/28438 tok/s;  22896 sec
[2019-10-07 02:37:58,451 INFO] Loading dataset from /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/data/ready_to_train.valid.0.pt
[2019-10-07 02:37:58,528 INFO] number of examples: 5006
[2019-10-07 02:38:05,953 INFO] Validation perplexity: 3.32166
[2019-10-07 02:38:05,953 INFO] Validation accuracy: 74.4215
[2019-10-07 02:38:05,953 INFO] Decreasing patience: 0/5
[2019-10-07 02:38:05,953 INFO] Training finished after not improving. Early Stop!
[2019-10-07 02:38:05,953 INFO] Best model found at step 19000
[2019-10-07 02:38:06,185 INFO] Saving checkpoint /media/barracuda4tb/dimitarsh1/Projects/BiasNMT/data/es-en-TRANS-BPE-NEW/model/model_step_22000.pt
